\chapter{Implementation and Methodologies}

This chapter describes the development methodology, organizational planning, implementation details, and deployment strategy adopted for the project. It emphasizes modular development, efficient project management, and robust deployment practices to ensure system reliability, scalability, and maintainability.

\section{Planning and Organization}

Effective planning and structured organization were fundamental to coordinate the development of multiple microservices and AI components. Two main approaches guided the project workflow: Agile methodology and Gantt chart planning.

\subsection{Gantt Chart}
A Gantt chart, designed in Excel, was used to visualize the overall timeline of the project, helping to split tasks among the team members, as shown in Figure \ref{fig:gantt}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/gantt.png} 
    \caption{Gantt Chart of the Project Schedule.}
    \label{fig:gantt}
\end{figure}

\subsection{Agile}
The development team adopted an Agile Kanban methodology to manage tasks and iterations efficiently. The Kanban board, integrated in Microsoft Teams, facilitated task prioritization, progress tracking, and rapid adaptation to evolving requirements, as reported in Figure \ref{fig:kanban}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/kanban.png} 
    \caption{Kanban Board on Microsoft Teams}
    \label{fig:kanban}
\end{figure}

\section{Development}

The development phase focused on realizing the architecture and functional requirements while adhering to best practices for code quality, modularity, and testability.

\subsection{Technology Stack and Tools}
The project leveraged modern technologies suitable for web-based, AI-driven systems:
\begin{itemize}
    \item \textbf{Backend}: Python with FastAPI for building RESTful APIs.
    \item \textbf{Frontend}: React for responsive, interactive user interface development.
    \item \textbf{Databases}: PostgreSQL for structured data (doctors, patients, reports), MongoDB for processed clinical data.
    \item \textbf{AI Libraries}: Pandas, Numpy, Scikit-Learn, XGBoost.
    \item \textbf{Version Control and Collaboration}: Git and GitHub.
    \item \textbf{Testing}: Pytest for unit and integration tests.
    \item \textbf{Containerization}: Docker for containers building and deployment.
\end{itemize}

\subsection{Class Diagrams}
Each microservice was implemented with well-defined classes to encapsulate business logic. Design patterns discussed in Section \ref{sec:design-patterns} were applied to improve maintainability, flexibility, and testability.

An overview of the UML class diagrams for all the services is reported below.

\subsubsection{Gateway}
To manage the complexity of interactions between the frontend and the distributed backend services, the Gateway component implements the Facade Design Pattern. The structural design of this component is shown in Figure \ref{fig:gat-class}.

The core of this implementation is the \texttt{GatewayFacade} class, which serves as the single entry point for all client requests. This class decouples the external API consumers from the underlying microservices by aggregating three specialized interfaces, each acting as a proxy for a specific internal domain.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/gateway-class.png} 
    \caption{UML Class Diagram of Gateway Service.}
    \label{fig:gat-class}
\end{figure}

\begin{itemize}
    \item \texttt{IAuthenticationClient}: This interface abstracts the communication with the Authentication Service. It defines methods for user management operations such as \texttt{register}, \texttt{login}, \texttt{validateToken}, and the password recovery workflow via \texttt{requestPasswordReset} and \texttt{resetPassword}.
    
    \item \texttt{IDataProcessingClient}: This interface encapsulates the interaction with the Data Processing Service. It exposes the \texttt{processData} method, which accepts an \texttt{AnalyseRequest} and returns the identifier of the processed data, handling the necessary anonymization and formatting steps transparently.
    
    \item \texttt{IExplainableAIClient}: This interface manages the connection to the Explainable AI Service. It provides the \texttt{performAnalysis} method to trigger the diagnostic process (specifying the \texttt{dataId} and the desired AI \texttt{mode}) and the \texttt{getReports} method to retrieve diagnostic history for specific patients.
\end{itemize}

\subsubsection{Authentication}
The Authentication Service is responsible for managing medical staff identities and securing access to the system. Its internal architecture, shown in Figure \ref{fig:auth-class}, relies heavily on the Repository and Observer design patterns to ensure separation of concerns and testability.

The core logic is encapsulated within the \texttt{AuthenticationService} class. This class orchestrates the registration and login workflows, utilizing internal helpers like \texttt{passwordHasher} for credential security and \texttt{jwtSigner} for issuing JSON Web Tokens.

To decouple the business logic from data persistence, the service implements the Repository Pattern through the \texttt{IUserRepository} interface.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/auth-class.png} 
    \caption{UML Class Diagram of Authentication Service.}
    \label{fig:auth-class}
\end{figure}

\begin{itemize}
    \item \texttt{IUserRepository}: Defines the contract for user data access. Methods such as \texttt{findByEmail} and \texttt{save} are used during registration and login.
    \item \texttt{UserRepositoryImpl}: The concrete implementation that handles the actual database connections and SQL queries.
\end{itemize}

Furthermore, to satisfy the traceability requirement without tightly coupling the authentication logic with the logging infrastructure, the service adopts the Observer Pattern via the \texttt{IAuditNotifier} interface.

\begin{itemize}
    \item \texttt{IAuditNotifier}: An abstraction that allows the service to emit events.
    \item \texttt{AuditClient}: The concrete implementation that asynchronously forwards these events to the Audit Service via REST API call.
\end{itemize}

\subsubsection{Data Processing}
The Data Processing Service handles the critical task of preparing raw clinical data for analysis while ensuring compliance with privacy standards. The internal architecture, illustrated in Figure \ref{fig:data-class}, is structured around the Chain of Responsibility Design Pattern to manage the data transformation pipeline efficiently.

The core of this pattern is defined by the \texttt{IProcessingStep} interface and the abstract \texttt{BaseProcessingStep} class, which allows for the dynamic linking of processing stages. The workflow is decomposed into discrete, sequential steps.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/data-class.png} 
    \caption{UML Class Diagram of Data Processing Service.}
    \label{fig:data-class}
\end{figure}

\begin{itemize}
    \item \texttt{ValidationStep}: The first link in the chain, responsible for verifying the integrity and format of the incoming raw data.
    \item \texttt{AnonymizationStep}: A critical component that implements the privacy requirements by hashing sensitive patient identifiers before storage.
    \item \texttt{EnrichmentStep}: The final stage that formats or augments the data to be compatible with the AI models.
\end{itemize}

The \texttt{DataProcessingService} class acts as the client that initiates this chain via the \texttt{chainHead} reference.

To handle data persistence and side effects, the service employs two additional abstractions:
\begin{itemize}
    \item \texttt{IProcessedDataRepository}: Implements the Repository Pattern to abstract the saving of anonymized data (\texttt{ProcessedData}) to the underlying NoSQL database.
    \item \texttt{IAuditNotifier}: Allows the service to asynchronously notify the central Audit system of processing events, maintaining the decoupling between data manipulation and logging logic.
\end{itemize}

\subsubsection{Explainable AI}
The Explainable AI Service represents the diagnostic core of the system. Its design is centered around the Strategy Design Pattern, which is essential to satisfy the swappable AI requirement, allowing the system to dynamically select the most appropriate analysis model at runtime. The class structure is illustrated in Figure \ref{fig:ai-class}.

The orchestrator of this component is the \texttt{ExplainableAIService} class. It relies on a set of abstractions to perform its tasks without being tightly coupled to specific implementations.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/ai-class.png} 
    \caption{UML Class Diagram of Explainable AI Service.}
    \label{fig:ai-class}
\end{figure}

\begin{itemize}
    \item Strategy Pattern Implementation: The logic for diagnostic analysis is encapsulated within the \texttt{IAnalysisStrategy} interface. Two concrete strategies implement this interface:
    \begin{itemize}
        \item \texttt{ClassicMLStrategy}: Implements the fast analysis mode using traditional Machine Learning models with SHAP-based explanations.
        \item \texttt{MultimodalStrategy}: Implements the deep analysis mode using Large Language Models with Chain-of-Thought reasoning.
    \end{itemize}
    The \texttt{StrategyFactory} class is responsible for instantiating the correct strategy based on the \texttt{mode} parameter received by the service.

    \item Repository Pattern: To manage the persistence of diagnostic reports, the service utilizes the \texttt{IReportRepository} interface. This allows the business logic to save and retrieve reports (filtered by doctor or patient) without handling the underlying database connection details.

    \item External Dependencies: The service interacts with other microservices through specific interfaces:
    \begin{itemize}
        \item \texttt{IProcessedDataClient}: Retrieves the anonymized and pre-processed data required for the analysis.
        \item \texttt{IAuditNotifier}: Asynchronously notifies the Audit Service of completed analyses, ensuring traceability.
    \end{itemize}
\end{itemize}

\subsubsection{Audit}
The Audit Service acts as the centralized logging facility for the entire architecture, satisfying the critical requirement of traceability. Its class design, shown in Figure \ref{fig:audit-class}, is intentionally minimal and optimized for write-intensive operations.

The architecture implements the Repository Design Pattern to abstract the persistence layer.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{images/audit-class.png} 
    \caption{UML Class Diagram of Audit Service.}
    \label{fig:audit-class}
\end{figure}

\begin{itemize}
    \item \texttt{AuditService}: This class serves as the entry point. It exposes the \texttt{logEvent} method, which receives \texttt{LogEventRequest} objects containing details such as timestamp, actor ID, and operation type.
    \item \texttt{ILogRepository}: This interface defines the contract for saving log entries, ensuring that the service logic is not coupled to the specific database technology.
    \item \texttt{LogRepositoryImpl}: The concrete implementation that manages the connection to the underlying SQL database, executing the actual insertion of the log records.
\end{itemize}

This separation ensures that the logging logic remains consistent even if the storage mechanism changes, maintaining high maintainability.

\subsection{Backend}
The codebase was organized into modular packages corresponding to the main microservices, each of which has separate folders for models, schemas, repositories, services, utilities, and API routes.

All microservices were implemented using FastAPI and are designed to communicate with each other through RESTful APIs. In order to allow seamless communication while maintaining isolation, Docker and Docker Compose were used to orchestrate the system. Each microservice has its own Dockerfile, defining its environment and dependencies, while Docker Compose is used to build and run all services together within a dedicated internal network.

Microservices communicate using the service names defined in the Docker Compose file as hostnames, and the internal ports defined in each Dockerfile. External ports are only exposed when necessary, e.g. for the Gateway or UI. This ensures that internal services cannot be reached directly from the outside, increasing security and reducing the risk of conflicts.

All client requests go through the Gateway, which then routes them to the appropriate internal microservice. This design ensures that internal services are never directly exposed to the UI or external network. Only the Gateway can communicate with them, while the UI communicates exclusively with the Gateway.

The following subsections aim to illustrate in detail the implementation choices adopted for the realization of the system.

\subsubsection{Databases}
The database architecture underpinning the microservices in this project plays a crucial role in ensuring data persistence, integrity, and scalability. While the system is logically organized as multiple independent microservices, each responsible for a specific domain, for practical purposes and to reduce deployment complexity, all logical databases have been implemented as separate tables within a single physical PostgreSQL instance. This approach allows each service to access only the tables relevant to its functionality, maintaining logical separation while simplifying database management and reducing overhead in the experimental or academic environment.

The PostgreSQL database contains two primary tables supporting the Authentication and Audit services. The \texttt{doctors} table stores information related to medical personnel, including a unique identifier, name, surname, email, and a cryptographically hashed password. Uniqueness constraints on the email field ensure that each doctor account is distinct, while primary key indexing facilitates efficient retrieval by identifier. This table is accessed exclusively by the Authentication service, which handles registration, login, and validation of doctor credentials.

The \texttt{logs} table supports the Audit service and serves as the central repository for event logging across the system. Each log entry includes a unique identifier, a timestamp of creation, the name of the service generating the log, the type of event, and a textual description. Optional fields allow association with a doctor, a hashed patient code, a data record, or a report, providing flexibility for auditing different domains. The Audit service writes events generated by various microservices into this table and allows filtered queries based on service, event type, or associated entities. Despite being stored in the same physical database, the Audit service logically isolates its operations to this table, ensuring clear separation of responsibilities.

The initial database state is seeded with example entries to illustrate typical events that occur in the system. These include successful and failed doctor registrations, login events, data processing activities, and operations related to explainable AI reports. This seeding provides a reference dataset for both testing and demonstration purposes, enabling the simulation of realistic workflows without depending on external data sources.

From a design perspective, this setup combines the advantages of microservice separation and simplified deployment. Each service interacts with its own logical schema, ensuring that responsibilities remain decoupled, while the single physical database reduces the complexity of managing multiple database instances. This choice also facilitates asynchronous and transactional operations through SQLAlchemy, allowing services to operate independently while maintaining data integrity and consistency. 

Overall, the database design supports the system's requirements for reliability, performance, and maintainability, enabling secure storage of user credentials and comprehensive logging of system events, while providing a flexible foundation for future extensions or migration to fully isolated physical databases if needed.

\subsubsection{Authentication Service}
In contemporary software development, particularly within microservice-oriented architectures, secure and scalable identity management represents a fundamental component for ensuring reliable system operation. The Authentication service developed in this project is designed to handle the registration, login, and validation of credentials for medical personnel, guaranteeing that only authorized users can access protected resources.

The service is implemented using Python 3.11 and relies on the FastAPI framework to provide asynchronous RESTful APIs through the ASGI interface. FastAPI was chosen due to its native support for asynchronous programming, which is crucial for efficiently handling a high volume of I/O-bound operations, such as the frequent database interactions required during authentication requests. For persistent data storage, PostgreSQL 15 is employed and accessed through SQLAlchemy 2.0 in fully asynchronous mode with the asyncpg driver. This approach prevents database operations from blocking other tasks, maximizing the efficient use of computational resources.

The internal structure of the service is organized following clean architecture principles, with distinct layers to separate responsibilities. At the core, the \texttt{Doctor} model defines the structure of the \texttt{doctors} table, including fields for the identifier, name, surname, email, and hashed password. The table is designed with integrity constraints such as unique email addresses and indexed primary keys, ensuring both correctness and performance in queries. Access to the database is abstracted through the Repository Pattern. The \texttt{IDoctorRepository} interface specifies the essential operations, including searching by identifier or email and saving new doctor records. The concrete implementation, \texttt{DoctorRepository}, executes these operations using asynchronous SQLAlchemy queries. This separation allows the service logic to remain decoupled from the underlying database operations, improving maintainability and enabling easier testing.

Input and output data are validated using Pydantic schemas. Classes such as \texttt{RegisterDoctorRequest}, \texttt{LoginDoctorRequest}, and \texttt{ValidateTokenRequest} enforce constraints on minimum string lengths, remove unnecessary whitespace, and validate email formats. Corresponding response models provide structured and predictable feedback to API consumers. This ensures that all interactions with the service follow a consistent contract, reducing the likelihood of runtime errors caused by invalid input data.

The core business logic is encapsulated in the \texttt{AuthenticationService} class, which handles the workflows for registration, login, and token validation independently of HTTP or database-specific concerns. Dependency Injection is applied via the \texttt{dependencies.py} module, which instantiates the service with concrete implementations of the \texttt{DoctorRepository}, \texttt{PasswordHasher}, and \texttt{JwtSigner}. This approach allows individual components to be easily replaced, for instance by changing the hashing algorithm or database engine, without requiring modifications to the service logic itself.

Security is enforced at multiple levels. Password management is delegated to the \texttt{PasswordHasher} class, which uses the Passlib library with the BCrypt algorithm. This ensures that passwords are hashed securely with automatic salting, and plaintext passwords are never stored in the database. Authentication sessions are managed through JSON Web Tokens generated by the \texttt{JwtSigner} class. Tokens include the user identifier and an expiration timestamp, and token validation is performed not only by verifying the cryptographic signature but also by checking the existence of the corresponding doctor in the database. This additional check prevents unauthorized access if an account has been deactivated.

A particularly distinctive feature of the service is the integration of the Observer pattern to improve auditability and logging. The \texttt{AuthenticationService} acts as the subject, maintaining a collection of observers that are asynchronously notified whenever significant events occur, such as successful or failed registrations, logins, or token validations. Observers implement the \texttt{IObserver} interface, which defines an asynchronous \texttt{update} method to receive event payloads. In this context, the \texttt{AuditClient} serves as a concrete observer, forwarding event information to an external audit microservice via HTTP POST requests. This design cleanly separates core authentication logic from cross-cutting concerns like auditing. When a doctor registers successfully, for example, the \texttt{notify} method is invoked, triggering asynchronous updates to all registered observers, allowing them to process the event independently of the main workflow.

The Observer pattern implementation provides multiple benefits in a microservices environment. It decouples the authentication logic from the audit service, supporting modularity and extensibility. Additional observers can be added without modifying existing code, enabling future monitoring, alerting, or analytics functionalities. Furthermore, because notifications are dispatched asynchronously, the main authentication processes are not blocked by the execution of external services, maintaining high performance and responsiveness.

Finally, the service exposes its functionality through FastAPI endpoints defined in the \texttt{authentication\_router.py} module. The registration endpoint handles creating new doctor records, hashing passwords, and notifying observers. The login endpoint verifies credentials and issues JWT tokens upon successful authentication. The token validation endpoint confirms the integrity and validity of JWT tokens while ensuring that the associated doctor exists in the system, triggering observer notifications in both success and failure scenarios. This architecture results in a robust, secure, and maintainable Authentication service, with the Observer pattern providing a flexible and scalable mechanism for handling cross-cutting concerns such as audit logging, aligning with best practices in microservices design.

\subsubsection{Audit Service}

The Audit service is designed to provide centralized and structured logging of significant events occurring throughout the microservices architecture. Its main purpose is to ensure traceability, accountability, and observability by recording key actions performed by the system or its users, including operations on sensitive resources, authentication events, and data access activities. This service plays a crucial role in supporting operational monitoring, debugging, and compliance requirements.

The service is implemented in Python 3.11 using FastAPI to expose asynchronous RESTful endpoints. Persistent storage is provided by PostgreSQL 15, accessed through SQLAlchemy 2.0 in asynchronous mode using the asyncpg driver. This architecture guarantees that high-frequency logging operations do not block other processes, preserving system responsiveness and throughput even under heavy load.

At the core of the service is the \texttt{Log} model, which maps to the \texttt{logs} table in the database. Each log entry contains a unique identifier, a timestamp indicating when the log was created, the name of the service that generated the log, the type of event, and a textual description. Additional optional fields allow association of a log with a specific doctor, a hashed patient code, a report identifier, or a data record identifier. This design enables the service to capture a wide range of events while maintaining a consistent and queryable structure.

Database access is abstracted by the Repository Pattern. The \texttt{ILogRepository} interface defines the contract for saving new logs, retrieving all logs, and querying logs with optional filters. Its concrete implementation, \texttt{LogRepository}, executes these operations asynchronously using SQLAlchemy, dynamically constructing query conditions based on the provided filter parameters. This separation ensures that the business logic in the service layer remains decoupled from database-specific concerns, promoting modularity and maintainability.

The \texttt{AuditService} class encapsulates the core business logic of the service. When a new event needs to be recorded, the \texttt{log} method creates a \texttt{Log} instance from the incoming request and persists it via the repository. For retrieving historical logs, the \texttt{get\_logs} method applies the provided filters and transforms the results into structured Pydantic models. Each response includes a message indicating whether logs were successfully retrieved or if no matching entries were found, providing clear and informative feedback to API consumers.

FastAPI endpoints are defined in the \texttt{audit\_router.py} module. The \texttt{/log} endpoint receives a request to create a new log and delegates it to the \texttt{log} method of the service, while the \texttt{/logs} endpoint allows clients to retrieve logs with optional filtering parameters. Dependency injection is used to supply the service with a repository instance through the \texttt{get\_audit\_service} function, ensuring that components remain decoupled and easily testable.

Overall, the Audit service provides a reliable and scalable solution for event logging in a microservices environment. Its architecture ensures that logs are created efficiently, stored in a structured and queryable format, and made available for retrieval in a manner that supports both machine processing and human analysis. By separating data persistence, business logic, and API exposure, the service maintains high modularity and performance, offering an essential tool for monitoring, auditing, and compliance across the entire system.

\subsection{Frontend}
DA SCRIVERE (palrare del framework UI e delle pagine come funzionano)


\section{Build and Deployment}
Deployment strategies focused on containerization and scalable hosting to ensure reproducibility and system availability. Docker was employed to encapsulate each microservice in independent containers, isolating dependencies and simplifying deployment.

The entire system is designed to be agnostic regarding the hosting infrastructure thanks to the use of Docker containerization. The \texttt{Dockerfile} has been optimized to reduce the final image size and speed up build times by separating the dependency installation phase from the source code copy to leverage Docker layer caching. Service orchestration is defined in the \texttt{docker-compose.yaml} file, which describes a complete environment composed of three interconnected services: the PostgreSQL database, the PgAdmin administration interface, and the authentication application service. Environment configuration takes place via environment variables defined in the \texttt{.env} file, separating configuration from code. Furthermore, a \texttt{db\_init.sql} initialization script is provided, which, upon the first startup of the database container, creates the table structure and populates the system with initial data, significantly facilitating development and testing phases.

The production deployment was carried out on a free Virtual Private Server (VPS) to ensure a secure and high-availability environment. Docker containers were used to deploy the system, with network configurations that expose the Gateway API and User Interface while restricting direct access to internal services. The deployment process was streamlined using Docker Compose, allowing the entire stack to be started with a single command.
\chapter{Development and Deployment}

This chapter describes the development methodology, organizational planning, implementation details, and deployment strategy adopted for the project. It emphasizes modular development, efficient project management, and robust deployment practices to ensure system reliability, scalability, and maintainability.

\section{Planning and Organization}

Effective planning and structured organization were fundamental to coordinate the development of multiple microservices and AI components. Two main approaches guided the project workflow: Agile methodology and Gantt chart planning.

\subsection{Gantt Chart}
A Gantt chart, designed in Excel, was used to visualize the overall timeline of the project, helping to split tasks among the team members, as shown in Figure \ref{fig:gantt}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/gantt.png} 
    \caption{Gantt Chart of the Project Schedule.}
    \label{fig:gantt}
\end{figure}

\subsection{Agile Methodology}
The development team adopted an Agile Kanban approach to manage tasks and iterations efficiently. The Kanban board, integrated in Microsoft Teams, facilitated task prioritization, progress tracking, and rapid adaptation to evolving requirements, as reported in Figure \ref{fig:kanban}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/kanban.png} 
    \caption{Kanban Board on Microsoft Teams}
    \label{fig:kanban}
\end{figure}

\section{Development}

The development phase focused on realizing the architecture and functional requirements while adhering to best practices for code quality, modularity, and testability.

\subsection{Technology Stack and Tools}
The project leveraged modern technologies suitable for web-based, AI-driven systems:
\begin{itemize}
    \item \textbf{Backend}: Python with FastAPI for building RESTful APIs.
    \item \textbf{Frontend}: React for responsive, interactive user interface development.
    \item \textbf{Databases}: PostgreSQL for structured data (doctors, patients, reports), MongoDB for processed clinical data.
    \item \textbf{AI Libraries}: Pandas, Numpy, Scikit-Learn, XGBoost.
    \item \textbf{Version Control and Collaboration}: Git and GitHub.
    \item \textbf{Testing}: Pytest for unit and integration tests.
    \item \textbf{Containerization}: Docker for containers building and deployment.
\end{itemize}

\subsection{Class Diagrams}
Each microservice was implemented with well-defined classes to encapsulate business logic. Design patterns discussed in Section \ref{sec:design-patterns} were applied to improve maintainability, flexibility, and testability.

An overview of the UML class diagrams for all the services is reported below.

\subsubsection{Gateway}
To manage the complexity of interactions between the frontend and the distributed backend services, the Gateway component implements the Facade Design Pattern. The structural design of this component is shown in Figure \ref{fig:gat-class}.

The core of this implementation is the \texttt{GatewayFacade} class, which serves as the single entry point for all client requests. This class decouples the external API consumers from the underlying microservices by aggregating three specialized interfaces, each acting as a proxy for a specific internal domain.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/gateway-class.png} 
    \caption{UML Class Diagram of Gateway Service.}
    \label{fig:gat-class}
\end{figure}

\begin{itemize}
    \item \texttt{IAuthenticationClient}: This interface abstracts the communication with the Authentication Service. It defines methods for user management operations such as \texttt{register}, \texttt{login}, \texttt{validateToken}, and the password recovery workflow via \texttt{requestPasswordReset} and \texttt{resetPassword}.
    
    \item \texttt{IDataProcessingClient}: This interface encapsulates the interaction with the Data Processing Service. It exposes the \texttt{processData} method, which accepts an \texttt{AnalyseRequest} and returns the identifier of the processed data, handling the necessary anonymization and formatting steps transparently.
    
    \item \texttt{IExplainableAIClient}: This interface manages the connection to the Explainable AI Service. It provides the \texttt{performAnalysis} method to trigger the diagnostic process (specifying the \texttt{dataId} and the desired AI \texttt{mode}) and the \texttt{getReports} method to retrieve diagnostic history for specific patients.
\end{itemize}

\subsubsection{Authentication}
The Authentication Service is responsible for managing medical staff identities and securing access to the system. Its internal architecture, shown in Figure \ref{fig:auth-class}, relies heavily on the Repository and Observer design patterns to ensure separation of concerns and testability.

The core logic is encapsulated within the \texttt{AuthenticationService} class. This class orchestrates the registration and login workflows, utilizing internal helpers like \texttt{passwordHasher} for credential security and \texttt{jwtSigner} for issuing JSON Web Tokens.

To decouple the business logic from data persistence, the service implements the Repository Pattern through the \texttt{IUserRepository} interface.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/auth-class.png} 
    \caption{UML Class Diagram of Authentication Service.}
    \label{fig:auth-class}
\end{figure}

\begin{itemize}
    \item \texttt{IUserRepository}: Defines the contract for user data access. Methods such as \texttt{findByEmail} and \texttt{save} are used during registration and login.
    \item \texttt{UserRepositoryImpl}: The concrete implementation that handles the actual database connections and SQL queries.
\end{itemize}

Furthermore, to satisfy the traceability requirement without tightly coupling the authentication logic with the logging infrastructure, the service adopts the Observer Pattern via the \texttt{IAuditNotifier} interface.

\begin{itemize}
    \item \texttt{IAuditNotifier}: An abstraction that allows the service to emit events.
    \item \texttt{AuditClient}: The concrete implementation that asynchronously forwards these events to the Audit Service via REST API call.
\end{itemize}

\subsubsection{Data Processing}
The Data Processing Service handles the critical task of preparing raw clinical data for analysis while ensuring compliance with privacy standards. The internal architecture, illustrated in Figure \ref{fig:data-class}, is structured around the Chain of Responsibility Design Pattern to manage the data transformation pipeline efficiently.

The core of this pattern is defined by the \texttt{IProcessingStep} interface and the abstract \texttt{BaseProcessingStep} class, which allows for the dynamic linking of processing stages. The workflow is decomposed into discrete, sequential steps.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/data-class.png} 
    \caption{UML Class Diagram of Data Processing Service.}
    \label{fig:data-class}
\end{figure}

\begin{itemize}
    \item \texttt{ValidationStep}: The first link in the chain, responsible for verifying the integrity and format of the incoming raw data.
    \item \texttt{AnonymizationStep}: A critical component that implements the privacy requirements by hashing sensitive patient identifiers before storage.
    \item \texttt{EnrichmentStep}: The final stage that formats or augments the data to be compatible with the AI models.
\end{itemize}

The \texttt{DataProcessingService} class acts as the client that initiates this chain via the \texttt{chainHead} reference.

To handle data persistence and side effects, the service employs two additional abstractions:
\begin{itemize}
    \item \texttt{IProcessedDataRepository}: Implements the Repository Pattern to abstract the saving of anonymized data (\texttt{ProcessedData}) to the underlying NoSQL database.
    \item \texttt{IAuditNotifier}: Allows the service to asynchronously notify the central Audit system of processing events, maintaining the decoupling between data manipulation and logging logic.
\end{itemize}

\subsubsection{Explainable AI}
The Explainable AI Service represents the diagnostic core of the system. Its design is centered around the Strategy Design Pattern, which is essential to satisfy the swappable AI requirement, allowing the system to dynamically select the most appropriate analysis model at runtime. The class structure is illustrated in Figure \ref{fig:ai-class}.

The orchestrator of this component is the \texttt{ExplainableAIService} class. It relies on a set of abstractions to perform its tasks without being tightly coupled to specific implementations.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{images/ai-class.png} 
    \caption{UML Class Diagram of Explainable AI Service.}
    \label{fig:ai-class}
\end{figure}

\begin{itemize}
    \item Strategy Pattern Implementation: The logic for diagnostic analysis is encapsulated within the \texttt{IAnalysisStrategy} interface. Two concrete strategies implement this interface:
    \begin{itemize}
        \item \texttt{ClassicMLStrategy}: Implements the fast analysis mode using traditional Machine Learning models with SHAP-based explanations.
        \item \texttt{MultimodalStrategy}: Implements the deep analysis mode using Large Language Models with Chain-of-Thought reasoning.
    \end{itemize}
    The \texttt{StrategyFactory} class is responsible for instantiating the correct strategy based on the \texttt{mode} parameter received by the service.

    \item Repository Pattern: To manage the persistence of diagnostic reports, the service utilizes the \texttt{IReportRepository} interface. This allows the business logic to save and retrieve reports (filtered by doctor or patient) without handling the underlying database connection details.

    \item External Dependencies: The service interacts with other microservices through specific interfaces:
    \begin{itemize}
        \item \texttt{IProcessedDataClient}: Retrieves the anonymized and pre-processed data required for the analysis.
        \item \texttt{IAuditNotifier}: Asynchronously notifies the Audit Service of completed analyses, ensuring traceability.
    \end{itemize}
\end{itemize}

\subsubsection{Audit}
The Audit Service acts as the centralized logging facility for the entire architecture, satisfying the critical requirement of traceability. Its class design, shown in Figure \ref{fig:audit-class}, is intentionally minimal and optimized for write-intensive operations.

The architecture implements the Repository Design Pattern to abstract the persistence layer.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{images/audit-class.png} 
    \caption{UML Class Diagram of Audit Service.}
    \label{fig:audit-class}
\end{figure}

\begin{itemize}
    \item \texttt{AuditService}: This class serves as the entry point. It exposes the \texttt{logEvent} method, which receives \texttt{LogEventRequest} objects containing details such as timestamp, actor ID, and operation type.
    \item \texttt{ILogRepository}: This interface defines the contract for saving log entries, ensuring that the service logic is not coupled to the specific database technology.
    \item \texttt{LogRepositoryImpl}: The concrete implementation that manages the connection to the underlying SQL database, executing the actual insertion of the log records.
\end{itemize}

This separation ensures that the logging logic remains consistent even if the storage mechanism changes, maintaining high maintainability.

\subsection{Databases}
DA SCRIVERE (parlare della progettazione E/R, dello schema delle tabelle, del database per service logico mappato su un solo db fisico con schemas sui tipi di dati e sull'ACID e postgresql, mongodb

\subsection{Backend}
The codebase was organized into modular packages corresponding to the main microservices, each of one has separate folders for models, schemas, repositories, services, utilities, and API routes.

The following subsections aim to illustrate in detail the implementation choices adopted for the realization of the system.

\subsubsection{Authentication}
In a modern software development context oriented towards microservices, secure and scalable identity management represents a critical foundation. The project was conceived to provide a mechanism for registration, access, and credential validation for medical personnel.

The technological foundation of the project is built around the Python language, specifically version 3.11. The core of the service consists of the FastAPI framework, a modern solution distinguished by its native use of asynchronous programming via the ASGI (Asynchronous Server Gateway Interface) specifications. This choice addresses the need to manage a high throughput of I/O-bound requests, such as those typical of an authentication service that constantly interacts with the database.

For data persistence management, the architecture employs PostgreSQL version 15, an open-source relational database known for its reliability and compliance with SQL standards. Interaction between the Python application and the database is mediated by SQLAlchemy version 2.0, utilized in a strictly asynchronous mode. Unlike traditional synchronous approaches, the combined use of SQLAlchemy with the \texttt{asyncpg} driver allows the server not to block execution during disk read and write operations, maximizing computational resource efficiency. The management of dependencies and support libraries includes tools such as \texttt{Pydantic} for data validation, \texttt{PyJWT} for security token management, and \texttt{Passlib} for password encryption.

The data flow traverses several well-distinct logical layers. At the outermost level, we find the definition of APIs and Data Transfer Objects (DTOs). The schema files, implemented via \texttt{Pydantic}, rigorously define the structure of requests and responses. For example, the \texttt{RegisterDoctorRequest} class applies preventive validation rules: text fields are cleaned of superfluous whitespace, the email is verified for syntactic compliance, and the password must respect minimum length requirements.

Proceeding towards the core of the system, we encounter the service layer, represented by the \texttt{AuthenticationService} class. This component encapsulates pure application logic, orchestrating registration, login, and validation operations without being aware of HTTP details or underlying SQL queries. Its independence is guaranteed by the use of Dependency Injection. The \texttt{dependencies.py} file serves as the Composition Root, where the various necessary components are instantiated and connected: the repository for data access, the utility for password hashing, and the JWT token manager. This Inversion of Control (IoC) mechanism is crucial for software quality, as it allows for the easy substitution of concrete implementations (for example, changing the database or hashing algorithm) without having to modify the code of the service that uses them.

Security is a transversal requirement that permeates the entire implementation. Password management is entrusted to the \texttt{PasswordHasher} class, which utilizes the \texttt{passlib} library and the BCrypt algorithm for hashing. BCrypt was chosen for its automatic use of salting. It is important to note that plain text passwords are never stored in the database, as the registration service immediately transforms them into cryptographic hashes before invoking the save operation.

In parallel, session authentication is managed in a stateless manner via JSON Web Tokens (JWT). The \texttt{JwtSigner} class is responsible for the creation and verification of these tokens. When a doctor logs in successfully, the system generates a token signed with the HS256 algorithm, containing the user identifier and a preset expiration date. This approach eliminates the need to maintain session state on the server, favoring horizontal scalability. Token validation is not limited to checking the cryptographic signature; the \texttt{validate\_token} method implements an additional referential integrity check, querying the database to ensure that the user associated with the token still exists, preventing unauthorized access in the case of deactivated accounts.

Data access is structured according to the Repository Pattern. The abstract interface \texttt{IDoctorRepository} defines the contract for operations on doctor data, such as searching by email or saving a new entity. Its concrete implementation, \texttt{DoctorRepository}, translates operations into asynchronous SQLAlchemy queries. The data model is defined in the \texttt{Doctor} class, which maps to the relational \texttt{doctors} table. The table structure includes essential integrity constraints, such as the uniqueness of the email field and the indexing of the primary key, ensuring optimal performance even as data volume grows. The use of the new SQLAlchemy 2.0 APIs allows for writing queries in a declarative and type-safe style, improving readability and reducing the possibility of runtime errors. Database connection is centrally managed by the \texttt{db\_connection.py} module, which configures the asynchronous engine and the session factory, ensuring that connection resources are used efficiently and released correctly at the end of every request.

\subsection{Frontend}
DA SCRIVERE (palrare del framework UI e delle pagine come funzionano)


\section{Deployment}
Deployment strategies focused on containerization and scalable hosting to ensure reproducibility and system availability. Docker was employed to encapsulate each microservice in independent containers, isolating dependencies and simplifying deployment.

\subsection{Containerization and Build}
The entire system is designed to be agnostic regarding the hosting infrastructure thanks to the use of Docker containerization. The \texttt{Dockerfile} has been optimized to reduce the final image size and speed up build times by separating the dependency installation phase from the source code copy to leverage Docker layer caching. Service orchestration is defined in the \texttt{docker-compose.yaml} file, which describes a complete environment composed of three interconnected services: the PostgreSQL database, the PgAdmin administration interface, and the authentication application service. Environment configuration takes place via environment variables defined in the \texttt{.env} file, separating configuration from code. Furthermore, a \texttt{db\_init.sql} initialization script is provided, which, upon the first startup of the database container, creates the table structure and populates the system with initial data, significantly facilitating development and testing phases.

The production deployment was carried out on a free Virtual Private Server (VPS) to ensure a secure and high-availability environment. Docker containers were used to deploy the system, with network configurations that expose the Gateway API and User Interface while restricting direct access to internal services. The deployment process was streamlined using Docker Compose, allowing the entire stack to be started with a single command.
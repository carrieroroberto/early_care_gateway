\chapter{State of the Art}

The contemporary healthcare landscape is characterized by an urgent need to optimize patient management processes, particularly in emergency settings where timeliness and accuracy are paramount. Facing challenges such as overcrowding and staff shortages, the medical sector is increasingly looking towards technological innovation to support decision-making.

This chapter provides a comprehensive overview of the current methodologies employed in clinical triage and preliminary diagnosis. It analyses the evolution from standardized manual protocols to advanced data-driven solutions, exploring the transformative potential of Artificial Intelligence by examining the limitations of traditional Machine Learning and the emerging capabilities of Large Language Models, highlighting the critical importance of explainability in fostering clinical adoption.

\section{Current Triage Protocols}
Among the technologies and protocols currently used to manage patient flow, the Manchester Triage System~\cite{zachariasse2017validity} is one of the most globally adopted frameworks. Functionally, it gives the nurses the possibility to assign a clinical priority to patients based on presenting symptoms, allocating them to one out of five categories depending on the urgency, with the ultimate aim of reducing queues in emergency facilities.

However, despite its widespread implementation, the efficacy of manual triage is not without flaws. According to a recent review by Andika et al.~\cite{andika2025effectiveness}, despite the system being widely adopted, it present some limitations. This study states that measurement errors are strictly linked to "personal factors" of the healthcare staff, leading to variability in decision-making. Moreover, this article states that, despite its efficacy, the issues of sub-triage (underestimating severity) and super-triage (overestimating severity) persist, and for these reasons there's the critical need to implement an automated, data-driven system that aims to mitigate human error and improve classification accuracy.

\section{The Role of Artificial Intelligence} 
One of the possible tools to address limitations of manual protocols is Artificial Intelligence, mainly divided into Traditional Machine Learning and Large Language Models. Historically, AI models such as Random Forest and Gradient Boosting have proven highly effective when applied in this field, allowing to reach tangible clinical benefits through structured data analysis. A systematic review by Sanchez et al.~\cite{sanchez2022machine} analyzed many machine learning methods applied to triage, concluding that these algorithms demonstrate consistency when it comes to accuracy, sensitivity and specificity when compared to traditional tools.

However, the study highlights a critical limitation, infact, while these algorithms perform really well with structured data (such as vital signs or tabular demographics), they struggle with unstructured data. To address this problem, the studies has shifted towards Large Language Models, commonly known as LLMs. While traditional algorithms rely on numerical inputs, these new implementations have the capability to process and interpret unstructured data, such as clinical notes and patient narratives.

As described by Thirunavukarasu et al.~\cite{thirunavukarasu2023large}, these models are really helpful thanks to their capabilities. Unlike traditional classifiers trained on specific tasks, LLMs are able to synthesize unstructured data and, above all, simulate clinical reasoning. Another really significative strenght of these models is their multimodal architecture, allowing them to integrate text, images and signals into a cohesive diagnostic suggestion.

\section{Explainability and Trust in Clinical AI} 
Despite the technical potential, the adoption of LLMs is not trusted by most medical professionals as they're reluctant to trust algorithms that provide diagnoses without an explanation (the so-called "Black Box" problem). To overcome this problem, the integration of Explainable AI techniques has become a must have for modern CDSS. According to a review by Loh et al.~\cite{loh2022application}, implementing explainability methods is essential to give trust and transparency to medical staff. Techniques such as SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) allow the system to highlight specificly which features influenced the model's decision, providing the clinician with the rationale behind the AI's output.

In conclusion, the current landscape highlights the need for a system that combines reliability of established medical protocols with the reasoning power of modern AI algorithms. The EarlyCare Gateway project is designed to cover all the aspect treated in this section within a secure and explainable architecture.